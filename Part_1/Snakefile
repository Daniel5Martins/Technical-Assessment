configfile: "config.yaml"

import os
import re
from glob import glob

ens = config["ensembl"]
fastq_dir = config["fastq_dir"]
ref_dir = config["ref_dir"]
ref_file = config["ref_file"]
qc_dir = config["qc_dir"]
log_dir = config["log_dir"]
bam_dir = config["bam_dir"]
thr = config["threads"]

samples, = glob_wildcards(os.path.join(fastq_dir, "{sample}_R1.fastq.gz"))

rule all:
    input:
        os.path.join(qc_dir, "final_multiqc.html")

rule make_dirs:
    output:
        touch("dirs_initialized.txt")
    shell:
        "mkdir -p {ref_dir} {log_dir} {qc_dir} {bam_dir} && touch {output}"

rule download_reference:
    # Download Reference genome
    output:
        fasta = ref_file,
        fasta_gz = temp(os.path.join(ref_dir, ens["fasta_file"]))
    message: "Downloading reference genome..."
    params:
        ensembl_url = f"ftp://ftp.ensembl.org/pub/release-{ens['release']}/fasta/{ens['species']}/dna/{ens['fasta_file']}"
    log:
        os.path.join(log_dir, "download_reference.log")
    threads: 1
    conda:
        "envs/ref_download.yaml"
    shell:
        # Use shell commands to verify if fasta.gz already exists
        """
            if [ ! -f {output.fasta_gz} ]; then
                wget -O {output.fasta_gz} {params.ensembl_url} > {log} 2>&1;
            fi
            gunzip -c {output.fasta_gz} > {output.fasta}
        """

rule index_reference:
    input:
        fasta = ref_file
    output:
        f"{ref_file}.fai",
        f"{ref_file}.amb",
        f"{ref_file}.ann",
        f"{ref_file}.bwt",
        f"{ref_file}.pac",
        f"{ref_file}.sa"
    message: "Reference genome index..."
    log:
        os.path.join(log_dir, "index_reference.log")
    threads: 4
    conda:
        "envs/alignment.yaml"
    shell:
        """
        bwa index {input.fasta} > {log} 2>&1
        samtools faidx {input.fasta} >> {log} 2>&1
        """

rule fastqc:
    input:
        r1 = os.path.join(fastq_dir, "{sample}_R1.fastq.gz"),
        r2 = os.path.join(fastq_dir, "{sample}_R2.fastq.gz")
    output:
        html_r1 = os.path.join(qc_dir, "{sample}_R1_fastqc.html"),
        zip_r1 = os.path.join(qc_dir, "{sample}_R1_fastqc.zip"),
        html_r2 = os.path.join(qc_dir, "{sample}_R2_fastqc.html"),
        zip_r2 = os.path.join(qc_dir, "{sample}_R2_fastqc.zip")
    message: "FastQC running on initial inputs..."
    log:
        os.path.join(log_dir, "{sample}_fastqc.log")
    threads: thr["fastqc"]
    conda:
        "envs/fastqc.yaml"
    shell:
        "fastqc {input.r1} {input.r2} -t {threads} -o {qc_dir} > {log} 2>&1"

rule trim_fastq:
    # Fastp to remove adapters from reads
    input:
        r1 = os.path.join(fastq_dir, "{sample}_R1.fastq.gz"),
        r2 = os.path.join(fastq_dir, "{sample}_R2.fastq.gz")
    output:
        # Standard trimmed outputs and HTML report. Output json file for downstream MultiQC
        r1 = os.path.join(fastq_dir, "{sample}_R1_trimmed.fastq.gz"),
        r2 = os.path.join(fastq_dir, "{sample}_R2_trimmed.fastq.gz"),
        html = os.path.join(qc_dir, "{sample}_fastp.html"),
        json = os.path.join(qc_dir, "{sample}_fastp.json")
    params:
        fastp_opts = config["tool_options"]["fastp_opts"]
    message: "Trimming..."
    log:
        # Store stdout and stderr together in log file, need to add "2>&1" on shell call
        os.path.join(log_dir, "{sample}_fastp.log")
    threads: thr["fastp"]
    conda:
        "envs/trimming.yaml"
    shell:
        """
            fastp \
            -i {input.r1} -I {input.r2} \
            -o {output.r1} -O {output.r2} \
            {params.fastp_opts} \
            --thread {threads} \
            --html {output.html} \
            --json {output.json} \
            > {log} 2>&1
        """

rule post_trim_fastqc:
    # Running FastQC after trimming for read quality comparison
    input:
        r1 = os.path.join(fastq_dir, "{sample}_R1_trimmed.fastq.gz"),
        r2 = os.path.join(fastq_dir, "{sample}_R2_trimmed.fastq.gz")
    output:
        # Standard FastQC output
        html_r1 = os.path.join(qc_dir, "{sample}_R1_trimmed_fastqc.html"),
        zip_r1 = os.path.join(qc_dir, "{sample}_R1_trimmed_fastqc.zip"),
        html_r2 = os.path.join(qc_dir, "{sample}_R2_trimmed_fastqc.html"),
        zip_r2 = os.path.join(qc_dir, "{sample}_R2_trimmed_fastqc.zip")
    message: "FastQC running on trimmed reads..."
    log:
        # Store stdout and stderr together in log file, need to add "2>&1" on shell call
        os.path.join(log_dir, "{sample}_trimmed.log")
    threads: thr["fastqc"]
    conda:
        "envs/fastqc.yaml"
    shell:
        "fastqc {input.r1} {input.r2} -t {threads} -o {qc_dir} > {log} 2>&1"


rule alignment:
    input:
        # Using trimmed reads
        r1 = os.path.join(fastq_dir, "{sample}_R1_trimmed.fastq.gz"),
        r2 = os.path.join(fastq_dir, "{sample}_R2_trimmed.fastq.gz"),
        ref = ref_file,
        ref_index = [
            f"{ref_file}.bwt",
            f"{ref_file}.pac",
            f"{ref_file}.ann",
            f"{ref_file}.amb",
            f"{ref_file}.sa",
            f"{ref_file}.fai",
        ]
    output:
        # Binary format - pipe to "samtools view" in shell command
        # It may be set to temporary "temp(...)" for storage optimization
        bam = os.path.join(bam_dir, "{sample}.bam")
    message: "Aligning reads..."
    log:
        os.path.join(log_dir, "{sample}_align.log")
    threads: thr["bwa"]
    conda:
        "envs/alignment.yaml"
    shell:
        # This pipeline assumes that reads were sequenced in an Illumina platform
        """
            bwa mem -t {threads} -R "@RG\\tID:{wildcards.sample}\\tSM:{wildcards.sample}\\tPL:ILLUMINA" \
            {input.ref} {input.r1} {input.r2} | \
            samtools view -Sb -q 20 > {output.bam} 2> {log}
        """

rule sort_bam:
    input:
        os.path.join(bam_dir, "{sample}.bam")
    output:
        os.path.join(bam_dir, "{sample}_sorted.bam")
    message: "BAM sorting..."
    log:
        os.path.join(log_dir, "{sample}_sort.log")
    threads: thr["samtools"]
    conda:
        "envs/alignment.yaml"
    shell:
        "samtools sort -@ {threads} -o {output} {input} > {log} 2>&1"

rule index_bam:
    input:
        os.path.join(bam_dir, "{sample}_sorted.bam")
    output:
        os.path.join(bam_dir, "{sample}_sorted.bam.bai")
    message: "BAM index..."
    log:
        os.path.join(log_dir, "{sample}_index.log")
    threads: 1
    conda:
        "envs/alignment.yaml"
    shell:
        "samtools index {input} > {log} 2>&1"

rule mark_duplicates:
    input:
        bam = os.path.join(bam_dir, "{sample}_sorted.bam"),
        bai = os.path.join(bam_dir, "{sample}_sorted.bam.bai")
    output:
        bam = os.path.join(bam_dir, "{sample}_markdup.bam"),
        metrics = os.path.join(qc_dir, "{sample}_markdup.metrics.txt")
    params:
        picard_opts = config["tool_options"]["picard_opts"]
    message: "Marking duplicates..."
    log:
        os.path.join(log_dir, "{sample}_markdup.log")
    threads: thr["picard"]
    conda:
        "envs/mark_dup.yaml"
    shell:
        """
            picard MarkDuplicates \
            I={input.bam} \
            O={output.bam} \
            M={output.metrics} \
            {params.picard_opts}
            > {log} 2>&1
        """

rule alignment_qc:
    input:
        bam = os.path.join(bam_dir, "{sample}_markdup.bam")
    output:
        flagstat = os.path.join(qc_dir, "{sample}_flagstat.txt"),
        idxstats = os.path.join(qc_dir, "{sample}_idxstats.txt"),
        stats = os.path.join(qc_dir, "{sample}_stats.txt")
    message: "Alignment QC..."
    log:
        flagstat = os.path.join(log_dir, "{sample}_flagstat.log"),
        idxstats = os.path.join(log_dir, "{sample}_idxstats.log"),
        stats = os.path.join(log_dir, "{sample}_stats.log")
    threads: thr["samtools"]
    conda:
        "envs/alignment.yaml"
    shell:
        """
            samtools flagstat {input.bam} > {output.flagstat} 2> {log.flagstat}
            samtools idxstats {input.bam} > {output.idxstats} 2> {log.idxstats}
            samtools stats {input.bam} > {output.stats} 2> {log.stats}
        """

rule final_multiqc:
    input:
        expand(os.path.join(qc_dir, "{sample}_fastp.html"),sample=samples),
        expand(os.path.join(qc_dir, "{sample}_fastp.json"),sample=samples),
        expand(os.path.join(qc_dir, "{sample}_R1_trimmed_fastqc.html"),sample=samples),
        expand(os.path.join(qc_dir, "{sample}_R1_trimmed_fastqc.zip"),sample=samples),
        expand(os.path.join(qc_dir, "{sample}_R2_trimmed_fastqc.html"),sample=samples),
        expand(os.path.join(qc_dir, "{sample}_R2_trimmed_fastqc.zip"),sample=samples),
        expand(os.path.join(qc_dir, "{sample}_markdup.metrics.txt"),sample=samples),
        expand(os.path.join(qc_dir, "{sample}_flagstat.txt"),sample=samples),
        expand(os.path.join(qc_dir, "{sample}_idxstats.txt"),sample=samples),
        expand(os.path.join(qc_dir, "{sample}_stats.txt"),sample=samples)
    output:
        os.path.join(qc_dir, "final_multiqc.html")
    message: "Generating final MultiQC report..."
    log:
        os.path.join(log_dir, "multiqc_final.log")
    threads: 1
    conda:
        "envs/multiqc.yaml"
    shell:
        """
            multiqc {input} \
            -o {qc_dir} \
            --filename final_multiqc.html 
            > {log} 2>&1
        """